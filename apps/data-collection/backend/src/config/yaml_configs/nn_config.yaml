nn_backend:
  type: "snpe"
  runtime: "dsp"
  performance_profile: "default"
  inference_threads: 1

tracker:
  track_per_class: true
  birth_threshold: 3
  max_lifespan: 90
  occlusion_ratio_threshold: 0.5
  tracker_threshold: 0.25

model:
  name: "yoloe"
  default_precision: "fp16"
  max_num_classes: 80
  confidence_threshold: 0.25

  quant_values:
    yoloe:
      quant_zero_point: 174.0
      quant_scale: 0.003328413470
    yoloe-image:
      quant_zero_point: 137.0
      quant_scale: 0.002327915514


  paths:
    tokenizer:
      url: "https://huggingface.co/openai/clip-vit-base-patch32/resolve/main/tokenizer.json"
      path: "tokenizer.json"

    text_encoder:
      url: "https://huggingface.co/Xenova/mobileclip_blt/resolve/main/onnx/text_model.onnx"
      path: "mobileclip_textual_hf.onnx"

    visual_encoder:
      url: "https://huggingface.co/sokovninn/yoloe-v8l-seg-visual-encoder/resolve/main/yoloe-v8l-seg_visual_encoder.onnx"
      path: "yoloe-v8l-seg_visual_encoder.onnx"
