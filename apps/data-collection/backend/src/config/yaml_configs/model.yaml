name: "yoloe"
default_precision: "fp16"
max_num_classes: 80
confidence_threshold: 0.25

quant_values:
  yoloe:
    quant_zero_point: 174.0
    quant_scale: 0.003328413470
  yoloe-image:
    quant_zero_point: 137.0
    quant_scale: 0.002327915514


paths:
  tokenizer:
    url: "https://huggingface.co/openai/clip-vit-base-patch32/resolve/main/tokenizer.json"
    path: "tokenizer.json"

  text_encoder:
    url: "https://huggingface.co/Xenova/mobileclip_blt/resolve/main/onnx/text_model.onnx"
    path: "mobileclip_textual_hf.onnx"

  visual_encoder:
    url: "https://huggingface.co/sokovninn/yoloe-v8l-seg-visual-encoder/resolve/main/yoloe-v8l-seg_visual_encoder.onnx"
    path: "yoloe-v8l-seg_visual_encoder.onnx"
