{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4dbb96e6",
   "metadata": {},
   "source": [
    "## Region-Based Mask Experiment Notebook\n",
    "\n",
    "This notebook starts fresh with a primitive region (patch) comparison approach for mask generation.\n",
    "\n",
    "Workflow:\n",
    "- Select two images (original & edited) from `inputs/`.\n",
    "- Auto-resize edited to match original if needed (toggle).\n",
    "- Slide a window (default 11x11) over both images.\n",
    "- For each window pair, apply a user-replaceable function that returns either a WHITE (255) or BLACK (0) patch in the mask.\n",
    "- Visualize Original | Edited | Patch-based Mask.\n",
    "- Save outputs with timestamp.\n",
    "\n",
    "You can easily experiment by editing `evaluate_patch(orig_patch, edit_patch, threshold)`.\n",
    "Add more sliders by following the pattern used for `patch_size` and `diff_threshold`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d175507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 image(s): ['3.png', 'me.png', 'pjs_2.jpg', 'tryon_result.jpg', 'tryon_result_jackie.jpg']\n"
     ]
    }
   ],
   "source": [
    "# Imports & paths setup\n",
    "import os, math\n",
    "from datetime import datetime\n",
    "import cv2\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "from pathlib import Path\n",
    "\n",
    "BASE_DIR = Path.cwd()  # assumes notebook opened from its directory\n",
    "INPUT_DIR = BASE_DIR / 'inputs'\n",
    "OUTPUT_DIR = BASE_DIR / 'outputs'\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def list_images():\n",
    "    exts = ('.png','.jpg','.jpeg','.bmp','.tif','.tiff')\n",
    "    if not INPUT_DIR.exists():\n",
    "        return []\n",
    "    return sorted([p.name for p in INPUT_DIR.iterdir() if p.suffix.lower() in exts])\n",
    "\n",
    "image_files = list_images()\n",
    "if not image_files:\n",
    "    print(f'No images found in {INPUT_DIR}. Add image files to proceed.')\n",
    "else:\n",
    "    print(f'Found {len(image_files)} image(s): {image_files}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e77443",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "937184413235476381f7cc8629c3e1e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Dropdown(description='Original:', options=('3.png', 'me.png', 'pjs_2.jpg', 'tryo…"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Widgets (re-usable pattern)\n",
    "if image_files:\n",
    "    orig_dropdown = widgets.Dropdown(options=image_files, description='Original:')\n",
    "    edited_dropdown = widgets.Dropdown(options=image_files, description='Edited:')\n",
    "else:\n",
    "    orig_dropdown = widgets.Dropdown(options=[''], description='Original:')\n",
    "    edited_dropdown = widgets.Dropdown(options=[''], description='Edited:')\n",
    "\n",
    "auto_resize = widgets.Checkbox(value=True, description='Auto-resize edited')\n",
    "patch_size = widgets.IntSlider(value=11, min=3, max=51, step=2, description='Patch size:', continuous_update=False)\n",
    "diff_threshold = widgets.IntSlider(value=25, min=0, max=255, step=1, description='Diff thresh:', continuous_update=False)\n",
    "invert_mask = widgets.Checkbox(value=False, description='Invert mask')\n",
    "show_grid = widgets.Checkbox(value=False, description='Show patch grid')\n",
    "\n",
    "# Sliders for YCrCb weighted L1 evaluator\n",
    "y_weight = widgets.FloatSlider(value=0.6, min=0.0, max=1.0, step=0.05, description='Y weight:', readout_format='.2f', continuous_update=False)\n",
    "cr_weight = widgets.FloatSlider(value=0.2, min=0.0, max=1.0, step=0.05, description='Cr weight:', readout_format='.2f', continuous_update=False)\n",
    "cb_weight = widgets.FloatSlider(value=0.2, min=0.0, max=1.0, step=0.05, description='Cb weight:', readout_format='.2f', continuous_update=False)\n",
    "\n",
    "controls = widgets.VBox([\n",
    "    widgets.HBox([orig_dropdown, edited_dropdown, auto_resize]),\n",
    "    widgets.HBox([patch_size, diff_threshold, invert_mask, show_grid]),\n",
    "    widgets.HBox([y_weight, cr_weight, cb_weight])\n",
    "])\n",
    "\n",
    "controls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e850a6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patch evaluation functions (color-aware)\n",
    "def evaluate_patch_grayscale(orig_patch: np.ndarray, edit_patch: np.ndarray, threshold: int) -> int:\n",
    "    \"\"\"Return 255 (white) or 0 (black) for the mask for this patch.\n",
    "\n",
    "    Strategy: simple absolute difference on mean intensity (grayscale).\n",
    "    Args:\n",
    "      orig_patch: (H,W,3) BGR patch\n",
    "      edit_patch: (H,W,3) BGR patch (same size)\n",
    "      threshold: scalar diff threshold (0-255)\n",
    "    Returns: 255 or 0\n",
    "    \"\"\"\n",
    "    orig_gray = cv2.cvtColor(orig_patch, cv2.COLOR_BGR2GRAY)\n",
    "    edit_gray = cv2.cvtColor(edit_patch, cv2.COLOR_BGR2GRAY)\n",
    "    diff = cv2.absdiff(orig_gray, edit_gray)\n",
    "    mean_diff = float(np.mean(diff))\n",
    "    return 255 if mean_diff >= threshold else 0\n",
    "\n",
    "def evaluate_patch_lab_deltaE(orig_patch: np.ndarray, edit_patch: np.ndarray, threshold: float) -> int:\n",
    "    \"\"\"Color difference via Lab space (CIE76 ΔE).\n",
    "\n",
    "    Converts patches to CIELAB and computes mean ΔE (Euclidean distance in Lab).\n",
    "    This is perceptually better than raw RGB differences and remains color-aware.\n",
    "\n",
    "    Args:\n",
    "      orig_patch: (H,W,3) BGR\n",
    "      edit_patch: (H,W,3) BGR\n",
    "      threshold: ΔE threshold (typical 5-30+; tune as needed)\n",
    "    Returns: 255 if mean ΔE >= threshold else 0\n",
    "    \"\"\"\n",
    "    lab1 = cv2.cvtColor(orig_patch, cv2.COLOR_BGR2LAB).astype(np.float32)\n",
    "    lab2 = cv2.cvtColor(edit_patch, cv2.COLOR_BGR2LAB).astype(np.float32)\n",
    "    delta = lab1 - lab2\n",
    "    deltaE = np.sqrt(np.sum(delta * delta, axis=2))\n",
    "    mean_deltaE = float(np.mean(deltaE))\n",
    "    return 255 if mean_deltaE >= float(threshold) else 0\n",
    "\n",
    "def evaluate_patch_ycrcb_weighted_l1(orig_patch: np.ndarray, edit_patch: np.ndarray, threshold: float, y_weight: float = 0.6, cr_weight: float = 0.2, cb_weight: float = 0.2) -> int:\n",
    "    \"\"\"Weighted L1 difference in YCrCb (color + luminance aware).\n",
    "\n",
    "    Separates luminance (Y) from chroma (Cr, Cb). By default weights emphasize\n",
    "    luminance while still accounting for color changes.\n",
    "\n",
    "    Args:\n",
    "      orig_patch: (H,W,3) BGR\n",
    "      edit_patch: (H,W,3) BGR\n",
    "      threshold: weighted diff threshold (scale ~0-255; tune with patch_size)\n",
    "      y_weight, cr_weight, cb_weight: channel weights that sum to ~1\n",
    "    Returns: 255 or 0\n",
    "    \"\"\"\n",
    "    ycc1 = cv2.cvtColor(orig_patch, cv2.COLOR_BGR2YCrCb).astype(np.float32)\n",
    "    ycc2 = cv2.cvtColor(edit_patch, cv2.COLOR_BGR2YCrCb).astype(np.float32)\n",
    "    ad = np.abs(ycc1 - ycc2)\n",
    "    w = np.array([y_weight, cr_weight, cb_weight], dtype=np.float32)\n",
    "    # per-pixel weighted L1 across channels\n",
    "    weighted = ad * w[None, None, :]\n",
    "    per_pixel = np.sum(weighted, axis=2)\n",
    "    mean_val = float(np.mean(per_pixel))\n",
    "    return 255 if mean_val >= float(threshold) else 0\n",
    "\n",
    "# # Default color-aware evaluate_patch: alias to Lab ΔE\n",
    "# def evaluate_patch(orig_patch: np.ndarray, edit_patch: np.ndarray, threshold: float) -> int:\n",
    "#     \"\"\"Alias to color-aware method (Lab ΔE CIE76).\"\n",
    "#     return evaluate_patch_lab_deltaE(orig_patch, edit_patch, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5f85504",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "937184413235476381f7cc8629c3e1e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Dropdown(description='Original:', options=('3.png', 'me.png', 'pjs_2.jpg', 'tryo…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3086c5aaf5ac43b2bdfad1fab60a08ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "244e7d2e90024934b75ecb42dba21f1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b19afccc1ea447499e1896f70cd0f435",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Processing and display\n",
    "import matplotlib.pyplot as plt\n",
    "last_mask = None\n",
    "out_area = widgets.Output()\n",
    "button_row = widgets.HBox([])\n",
    "\n",
    "# Advanced ECC alignment using only top/bottom borders\n",
    "def ecc_align_borders(orig_bgr: np.ndarray, edit_bgr: np.ndarray, border_px: int = 200, warp_mode: int = cv2.MOTION_AFFINE):\n",
    "    \"\"\"Align edit_bgr to orig_bgr using ECC computed on only top/bottom borders.\n",
    "    Steps:\n",
    "    - Ensure same size (caller should have resized edit beforehand if needed)\n",
    "    - Convert to grayscale float32 in [0,1]\n",
    "    - Zero out the center region so ECC focuses on borders\n",
    "    - Estimate warp with findTransformECC\n",
    "    - Warp full color image with the estimated transform\n",
    "    Fallback: return edit_bgr unchanged on failure.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        h, w = orig_bgr.shape[:2]\n",
    "        # Prepare grayscale float32 normalized\n",
    "        orig_gray = cv2.cvtColor(orig_bgr, cv2.COLOR_BGR2GRAY).astype(np.float32) / 255.0\n",
    "        edit_gray = cv2.cvtColor(edit_bgr, cv2.COLOR_BGR2GRAY).astype(np.float32) / 255.0\n",
    "\n",
    "        # Mask out center by zeroing it; keep only top and bottom stripes\n",
    "        b = max(0, min(border_px, h // 2))\n",
    "        if b > 0:\n",
    "            orig_gray_masked = np.zeros_like(orig_gray)\n",
    "            edit_gray_masked = np.zeros_like(edit_gray)\n",
    "            # top stripe\n",
    "            orig_gray_masked[0:b, :] = orig_gray[0:b, :]\n",
    "            edit_gray_masked[0:b, :] = edit_gray[0:b, :]\n",
    "            # bottom stripe\n",
    "            orig_gray_masked[h-b:h, :] = orig_gray[h-b:h, :]\n",
    "            edit_gray_masked[h-b:h, :] = edit_gray[h-b:h, :]\n",
    "        else:\n",
    "            # If border is 0, just use full images (unlikely here)\n",
    "            orig_gray_masked = orig_gray\n",
    "            edit_gray_masked = edit_gray\n",
    "\n",
    "        # Initialize warp matrix\n",
    "        if warp_mode == cv2.MOTION_HOMOGRAPHY:\n",
    "            warp_matrix = np.eye(3, 3, dtype=np.float32)\n",
    "        else:\n",
    "            warp_matrix = np.eye(2, 3, dtype=np.float32)\n",
    "\n",
    "        criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 300, 1e-6)\n",
    "        # ECC estimation\n",
    "        cc, warp_matrix = cv2.findTransformECC(orig_gray_masked, edit_gray_masked, warp_matrix, warp_mode, criteria)\n",
    "\n",
    "        # Warp the color image with the found transform\n",
    "        if warp_mode == cv2.MOTION_HOMOGRAPHY:\n",
    "            aligned = cv2.warpPerspective(edit_bgr, warp_matrix, (w, h), flags=cv2.INTER_LINEAR + cv2.WARP_INVERSE_MAP, borderMode=cv2.BORDER_REFLECT)\n",
    "        else:\n",
    "            aligned = cv2.warpAffine(edit_bgr, warp_matrix, (w, h), flags=cv2.INTER_LINEAR + cv2.WARP_INVERSE_MAP, borderMode=cv2.BORDER_REFLECT)\n",
    "        return aligned\n",
    "    except Exception as e:\n",
    "        print(f'ECC alignment failed: {e}')\n",
    "        return edit_bgr\n",
    "\n",
    "def build_patch_mask(orig: np.ndarray, edit: np.ndarray, psize: int, threshold: int, invert: bool, show_grid_flag: bool, y_w: float, cr_w: float, cb_w: float) -> np.ndarray:\n",
    "    h, w = orig.shape[:2]\n",
    "    mask = np.zeros((h, w), dtype=np.uint8)\n",
    "    # iterate top-left corners stepping by psize\n",
    "    for y in range(0, h, psize):\n",
    "        for x in range(0, w, psize):\n",
    "            y2 = min(y + psize, h)\n",
    "            x2 = min(x + psize, w)\n",
    "            orig_patch = orig[y:y2, x:x2]\n",
    "            edit_patch = edit[y:y2, x:x2]\n",
    "            # skip if patch shape mismatch\n",
    "            if orig_patch.shape != edit_patch.shape:\n",
    "                continue\n",
    "            # val = evaluate_patch_ycrcb_weighted_l1(orig_patch, edit_patch, threshold, y_weight=float(y_w), cr_weight=float(cr_w), cb_weight=float(cb_w))\n",
    "            # val = evaluate_patch_grayscale(orig_patch, edit_patch, threshold)\n",
    "            val = evaluate_patch_lab_deltaE(orig_patch, edit_patch, threshold)\n",
    "            if invert:\n",
    "                val = 255 - val\n",
    "            mask[y:y2, x:x2] = val\n",
    "            if show_grid_flag:\n",
    "                # outline patches lightly (set border to mid-gray if mask white)\n",
    "                cv2.rectangle(mask, (x, y), (x2-1, y2-1), 128 if val==255 else 64, 1)\n",
    "    return mask\n",
    "\n",
    "def run_pipeline(orig_name, edited_name, psize, threshold, invert_mask_val, show_grid_val, auto_resize_val, y_w, cr_w, cb_w):\n",
    "    global last_mask\n",
    "    out_area.clear_output(wait=True)\n",
    "    with out_area:\n",
    "        if not orig_name or not edited_name or orig_name == edited_name:\n",
    "            print('Select two different images.')\n",
    "            last_mask = None\n",
    "            return None\n",
    "        op = str(INPUT_DIR / orig_name)\n",
    "        ep = str(INPUT_DIR / edited_name)\n",
    "        orig = cv2.imread(op)\n",
    "        edit = cv2.imread(ep)\n",
    "        if orig is None or edit is None:\n",
    "            print('Failed to read one or both images.')\n",
    "            last_mask = None\n",
    "            return None\n",
    "        # Ensure same dims, then optionally run ECC alignment based on borders\n",
    "        if orig.shape[:2] != edit.shape[:2]:\n",
    "            if auto_resize_val:\n",
    "                edit = cv2.resize(edit, (orig.shape[1], orig.shape[0]), interpolation=cv2.INTER_LINEAR)\n",
    "            else:\n",
    "                print('Size mismatch; enable auto-resize.')\n",
    "                last_mask = None\n",
    "                return None\n",
    "        if auto_resize_val:\n",
    "            # refine alignment using ECC on borders (top/bottom 200px)\n",
    "            edit = ecc_align_borders(orig, edit, border_px=500, warp_mode=cv2.MOTION_AFFINE)\n",
    "\n",
    "        mask = build_patch_mask(orig, edit, int(psize), int(threshold), invert_mask_val, show_grid_val, float(y_w), float(cr_w), float(cb_w))\n",
    "        last_mask = mask\n",
    "        # display side-by-side\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(12, 12)) # Stop changing this from 12 to 3!\n",
    "        axes[0].imshow(cv2.cvtColor(orig, cv2.COLOR_BGR2RGB)); axes[0].set_title('Original'); axes[0].axis('off')\n",
    "        axes[1].imshow(cv2.cvtColor(edit, cv2.COLOR_BGR2RGB)); axes[1].set_title('Edited'); axes[1].axis('off')\n",
    "        axes[2].imshow(mask, cmap='gray'); axes[2].set_title('Patch Mask'); axes[2].axis('off')\n",
    "        fig.tight_layout(); plt.show()\n",
    "        return mask\n",
    "\n",
    "ui = widgets.interactive_output(run_pipeline, {\n",
    "    'orig_name': orig_dropdown,\n",
    "    'edited_name': edited_dropdown,\n",
    "    'psize': patch_size,\n",
    "    'threshold': diff_threshold,\n",
    "    'invert_mask_val': invert_mask,\n",
    "    'show_grid_val': show_grid,\n",
    "    'auto_resize_val': auto_resize,\n",
    "    'y_w': y_weight,\n",
    "    'cr_w': cr_weight,\n",
    "    'cb_w': cb_weight\n",
    "})\n",
    "display(controls)\n",
    "display(out_area)\n",
    "display(button_row)\n",
    "display(ui)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7223dd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save functionality (uses last_mask cache)\n",
    "status_label = widgets.HTML(value='')\n",
    "save_btn = widgets.Button(description='Save mask', button_style='success', icon='save')\n",
    "\n",
    "def save_mask(_=None):\n",
    "    global last_mask\n",
    "    if last_mask is None:\n",
    "        status_label.value = '<em>No mask to save.</em>'\n",
    "        return\n",
    "    ts = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    out_path = OUTPUT_DIR / f'patch_mask_{ts}.png'\n",
    "    cv2.imwrite(str(out_path), last_mask)\n",
    "    status_label.value = f'Saved: {out_path.name}'\n",
    "\n",
    "save_btn.on_click(save_mask)\n",
    "button_row.children = [save_btn, status_label]\n",
    "button_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07da831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Programmatic quick test (optional)\n",
    "if len(image_files) >= 2:\n",
    "    orig_dropdown.value = image_files[0]\n",
    "    edited_dropdown.value = image_files[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
